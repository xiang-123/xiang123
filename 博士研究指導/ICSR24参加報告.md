# ICSR24学会参加報告
- 2024/11/11
- 10~15分

# 学会
-  [the 16th International Conference on Social Robotics(ICSR24)](https://icsr2024.dk/)
    - 目的：bring together researchers and practitioners working on **the interaction between humans and intelligent robots and on the integration of social robots into our society.**（人と知能ロボットの相互作用、社会におけるソーシャルロボットの統合）
    - 今年のテーマ：Empowering Humanity: The Role of Social and Collaborative Robotics in Shaping Our Future（人類への力を：未来を形作るソーシャルロボットと協働ロボットの役割）
    - 対象：The conference welcomes original contributions describing technically rigorous scientific and research advances in the area of social robotics and AI:
Innovative ideas and concepts, new discoveries and improvements, novel applications on the latest fundamental advances in the core technologies that form the backbone of social robotics as well as distinguished studies and projects pertaining the social robotics and its interaction and impact in our society. （この会議では、ソーシャルロボティクスおよびAI分野における技術的に厳密な科学的および研究上の進展を記述する独創的な貢献を歓迎します。ソーシャルロボティクスの基盤を形成する最新の基礎技術における革新的なアイデアや概念、新しい発見や改善、そして新規アプリケーション、さらにソーシャルロボティクスとその社会における相互作用と影響に関する優れた研究やプロジェクトも対象としています。）
    - トピック：
        <img width="600" alt="スクリーンショット 2024-11-11 10 40 22" src="https://github.com/user-attachments/assets/071f6efb-7ce2-4526-945a-449f836f5532">
-  10/23-10/26, @Odense, Denmark
- 全体的な感想
    - 今回の会議はSocial robotsに関する研究が中心で、VRやappなどの多様なロボットではなく、実体のある擬人化ロボット（サービスロボット、医療ロボット、対話ロボットなど）に特化しました。自分にとって研究方向や使用する方法が似ているため、Social robots を対象とするhuman-robot interaction分野の最新の進展を把握しやすいと感じました。また、似ているアプローチを取っている研究者とも知り合うことができました。

# 写真
## @Copenhagen
- コペンハーゲン空港(10/22→10/23,Denmark)
    - <img width="500" alt="スクリーンショット 2024-11-11 10 50 22" src="https://github.com/user-attachments/assets/0d046e70-d3b6-4d3c-8647-5110a0a73257">
    - <img width="500" alt="スクリーンショット 2024-11-11 10 55 14" src="https://github.com/user-attachments/assets/c5507098-d425-4e6d-b6f1-12acbaeae836">
- コペンハーゲン中央駅(10/22,Denmark)
    - <img width="500" alt="スクリーンショット 2024-11-11 10 51 43" src="https://github.com/user-attachments/assets/df9d9384-b4bb-4ec8-a6da-b168c1f77c05">
    - <img width="500" alt="スクリーンショット 2024-11-11 10 55 57" src="https://github.com/user-attachments/assets/30c57fdc-b50f-4014-850c-80e3818ed7a2">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 05 07" src="https://github.com/user-attachments/assets/37a91b7d-30a3-479c-9746-f40df9e0160c">
- City(10/27,Denmark)
    - <img width="500" alt="スクリーンショット 2024-11-11 11 33 52" src="https://github.com/user-attachments/assets/46fd5f88-f872-4724-a750-4bd45ab1a31b">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 34 03" src="https://github.com/user-attachments/assets/f3c3c421-e278-49f1-be90-a736b08a8282">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 36 05" src="https://github.com/user-attachments/assets/292c390c-30d9-435d-aa22-b5b5ad513c06">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 36 17" src="https://github.com/user-attachments/assets/afa670e5-dfad-4ab5-ac76-87b1b5954a4a">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 36 27" src="https://github.com/user-attachments/assets/973ae68f-9c1c-4330-9fa5-3e57c40b8ba0">

## @Odense(10/23-26,Denmark)
- Odense駅(10/23 Day1,Denmark)
    - <img width="500" alt="スクリーンショット 2024-11-11 10 59 48" src="https://github.com/user-attachments/assets/ec432066-91b0-4bd2-bf0c-b07b6a7ef4bb">
- City(10/23-26,Denmark)   
    - <img width="500" alt="スクリーンショット 2024-11-11 11 01 21" src="https://github.com/user-attachments/assets/fd5a01f6-01a3-45d8-b624-a392b744e21e">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 02 01" src="https://github.com/user-attachments/assets/baebf7cc-d7fd-45c9-9173-1a79b4f34d4a">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 32 16" src="https://github.com/user-attachments/assets/46cb7b12-0096-4a3e-a127-8330722de256">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 32 34" src="https://github.com/user-attachments/assets/c787bc24-d3db-41bc-b3f6-e4cbe07e2311">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 32 58" src="https://github.com/user-attachments/assets/8e7a64c4-910b-4755-890f-34a15675689c">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 33 12" src="https://github.com/user-attachments/assets/0f5afa92-90a7-4886-a024-1719387c0be0">

- @University of Southern Denmark(10/23 Day1,Denmark)
    - <img width="500" alt="スクリーンショット 2024-11-11 11 06 26" src="https://github.com/user-attachments/assets/5126312a-21f6-4bd8-83bd-f30be65115f6">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 08 39" src="https://github.com/user-attachments/assets/4979845c-d320-4a25-a055-b5b6914af8c0">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 09 26" src="https://github.com/user-attachments/assets/b3ea1e33-5e36-41dc-b943-73462c6a3501">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 09 59" src="https://github.com/user-attachments/assets/34d64ebd-eb86-466c-b27f-f2ea962e74c2">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 10 40" src="https://github.com/user-attachments/assets/015eb8d0-6572-4f28-b6fd-2dad8226b6d6">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 11 41" src="https://github.com/user-attachments/assets/7edd518c-0f8b-4959-b8e3-09c56c19115a">
- 学会会場@Odeon(10/25-26 Day2-3,Denmark)
    - <img width="500" alt="スクリーンショット 2024-11-11 11 13 19" src="https://github.com/user-attachments/assets/39fca932-39e9-448b-9551-c870e7861328">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 14 14" src="https://github.com/user-attachments/assets/fb64ce73-3917-42f9-aa53-14b56e3fce01">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 14 39" src="https://github.com/user-attachments/assets/8004a5e6-a563-4b56-96f8-73b30fd41ffc">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 16 10" src="https://github.com/user-attachments/assets/46f82dd9-83b5-4a21-8c5a-9f44044ecee2">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 17 46" src="https://github.com/user-attachments/assets/b78625ab-d733-4f11-a4dc-b16949a8fedd">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 20 40" src="https://github.com/user-attachments/assets/d0f129a1-1e00-46b1-a6b4-5b5e0920af53">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 21 08" src="https://github.com/user-attachments/assets/aff58814-df6f-424d-8148-faf473ba1f7b">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 16 32" src="https://github.com/user-attachments/assets/f70c8a12-7a59-4602-8dda-96b46b6b425a">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 22 04" src="https://github.com/user-attachments/assets/ca0927e9-1687-4bb3-b7e8-89d0f3f300a7">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 17 20" src="https://github.com/user-attachments/assets/49c9d70c-23a2-4063-b0ef-58b4e543e058">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 18 11" src="https://github.com/user-attachments/assets/72afacb9-1b74-4207-8818-6d6dd1454279">

# 発表
## 聴講した発表
### workshop:[Personalized social robots to support successful Aging](https://sites.google.com/view/personalizedsocialrobotstosupp/home?authuser=0)
- Personalized robot
    - <img width="500" alt="スクリーンショット 2024-11-11 12 04 29" src="https://github.com/user-attachments/assets/d7ea36c5-e533-4071-b98b-a8c8370109d9">
    - 高齢者介護施設でのソーシャルロボット：メニューの選択を収集、薬のリマインド、認知療法を行う
    - 仕事の重点は、やり取りをする相手に口頭で説明を提供すること（相手：a resident, a family member, nurse, or technician）
    - 口頭での説明は、相手に合わせて個別に調整する必要ある
#### 感想
- これから研究対象を高齢者とする予定があるため、これらのworkshopに参加しました。しかし、内容は高齢者のケア、サービスロボット、高齢者向けのウェアラブルデバイスに関するもので、使用されている手法もECGなどの生体情報が中心で、アンケートやインタビューを使う私の研究とはあまり似ていないです。
- 個人的に印象深かった点:このworkshopで高齢者向けロボットの設計や応用における重要な課題と改善の可能性について議論されていました。
    - 例えば、実際の生活環境は実験室や教室などのように静かではないため、騒がしい部屋でも高齢者と円滑に対話できることが重要とされていました。また、高齢者の聴覚は一般の若者よりも衰えていることが多いため、ロボット設計時には環境の騒音レベルや高齢者の聴力を考慮し、必要に応じて音量を調整する必要があると勉強しました。さらに、私たちが研究を進めるとき、「when」「what」「how」を考えることの重要性に気づきました。例えば、「いつコミュニケーションをとるか？」「何を伝えるべきか？」「どのように伝えるか？」といったポイントを明確にした上で研究を進める必要があると感じました。
- パーソナライズのメリット＆課題
    - メリット：高齢者支援（supporting staff, automating repetitive tasks:薬のリマインドなど）、個々のニーズや好みに応じた適応（例: 認知療法、運動）
    - 課題
        - Stigmatization
        - 例：孤独感（人間ではなくソーシャルロボットと一緒にいると、「孤立している」と感じてしまい、孤独感やネガティブ感情が増える可能性がある）、社会的地位（ソーシャルロボットによる支援を受けることで、一部の人々は自分が「介護を必要とする」弱者だと感じてしまい、恥ずかしいと思う）、individual stigma（日常生活のタスクをロボットに頼ることが自分の能力低下を意味していると思い、自分のことを否定する気持ちが生まれる可能性があります。自信やメンタルヘルスに影響を与えるかもしれない）

### The Content of Transparency Matters: Evaluating Verbal Transparency about Robot Capabilities
- social robotにおけるtrust calibration（信頼較正）に関する研究
- <img width="500" alt="スクリーンショット 2024-11-11 12 33 16" src="https://github.com/user-attachments/assets/feb01b2a-3d32-4dc4-b2c5-7e0ca2f8f641">
- <img width="500" alt="スクリーンショット 2024-11-11 12 33 48" src="https://github.com/user-attachments/assets/8ce87ded-bb1e-4ee5-8324-388ae4f58c16">
    - 目的
        - ロボットの透明性のある（Transparency）発話が、ロボットの信頼性の認知（Trustworthiness）にどのような影響を与えるかを調査しました。
    - 方法
        - 研究は[Prolific](https://www.prolific.com/)を使い、参加者にシナリオ化されたビデオを見せ、参加者がロボットに「Can you close the window, please?窓を閉めてください」と頼むという場面を設定しています。実験では4つのグループに分けられました：
（グループ1）低レベルの能力＋透明性あり（例：「Can you close the window, please? I will close it.」）→自分が何をしているかを簡単に説明
（グループ2）高レベルの能力＋透明性なし（例：「I will close it.」）→なぜそれが可能なのか説明がなく、ユーザーにとって不透明
（グループ3）高レベルの能力＋透明性あり（例：「Yes, I can operate the window. I will close it.」）→能力を持っていることをユーザーに伝えることで、信頼を築くための情報を提供
（グループ4）ベースライン（音だけの反応、Beep）→言葉での応答がなく、能力も透明性も含まれてない
        - 「高レベル」と「低レベル」：ロボットが応答する際の知能のレベルや能力の高さ
        - 「透明性あり」と「透明性なし」：ロボットが自分の行動の説明をどれだけ明確に行うか
        - 参加者にはこの4つのビデオを視聴してもらい、その後、アンケートで信頼性を測定しました。結果として、グループ1と3が信頼性評価で最も高く、グループ2はグループ1と3に比べて有意に低い評価となり、グループ4が最も低い評価でした。
- 感想
    - 私の研究方法と似ている点があり（私は実際の対話を用いたのに対し、彼らはシナリオビデオを用いました）、特に「信頼を築くことだけでなく、ロボットの能力と信頼性を正確に反映すること」(Perceived Trustworthiness)が重要であると感じました。trust calibrationの目的は、人とロボットの効果的なインタラクションを促進することです。
    - 最初はこの研究がロボットによる家電の信頼性についてであると思っていましたが、発表者に聞きました。実際にはロボットが窓を閉めることはできないという設定です。これは、私が考えた「行為提供型」のencouragementが実際の行為を伴わないことと似ていると思い、この研究も完全にシナリオに基づいているものでした。
    - ただし、現段階ではこの研究のcontributionが完全には理解できない部分もありましたが、oral presentationだけ聴講しましたので、論文が発表されたら再度確認したいと思います。

### [keynote: Takayuki Kanda](https://icsr2024.dk/index.php/keynotes/#Kanda)
- ロボットが現実世界で直面する難しさを紹介しました。
- <img width="500" alt="スクリーンショット 2024-11-11 12 53 37" src="https://github.com/user-attachments/assets/35cdb2f0-8316-4051-b51a-44ea2625a429">
- <img width="500" alt="スクリーンショット 2024-11-11 12 54 11" src="https://github.com/user-attachments/assets/feaf0422-b4ca-46a6-8722-ea13202334e8">
- <img width="500" alt="スクリーンショット 2024-11-11 12 56 29" src="https://github.com/user-attachments/assets/19fad0d3-31b7-4941-9a2d-63c9b035d67b">
- <img width="500" alt="スクリーンショット 2024-11-11 12 56 45" src="https://github.com/user-attachments/assets/55ddc55a-650c-4c96-b90d-5db20fcb80d7">
- <img width="500" alt="スクリーンショット 2024-11-11 12 54 35" src="https://github.com/user-attachments/assets/8e53ed44-32a0-40af-9cf1-9cf4603a57a1">
- 研究者たちは多くの現実世界のビデオ録画を通じて、ロボットと人間の社会的な距離や、人間がロボットに対して寛容でいるのか、虐待するのか、尊重するのか、無視するのかといった反応を観察しました。このような状況でロボットを活用するには、適切な社会的・道徳的な相互作用が必要であることが強調されていました。

### combining control and validity: context management issues in proactive social robotics research
- <img width="500" alt="スクリーンショット 2024-11-11 13 00 44" src="https://github.com/user-attachments/assets/33a72fe9-4834-47b2-939d-b5854022073e">
- 内容
    - （a）社会ロボティクス研究において構築された環境を使用することが外部および内部の妥当性に与える可能性のある影響を考察
    - （b）解決が必要なコンテキスト管理の問題を説明
- ソーシャルロボティクス研究における自然環境と構築環境
    - 「自然-コントロール」
    - 環境、タスク、技術、および技術の所有権
- 大事だと思う点：Table1. Typs of studies in social robotics: the "natural-controlled" dimension
    - <img width="600" alt="スクリーンショット 2024-11-11 14 18 17" src="https://github.com/user-attachments/assets/50b7adfe-fd58-4575-bb80-bd5e8f0a681a">
- 感想
    - 修士研究:Constructed → Field testing + Not short-term + Controlled experiment　→　WoZ and higher fidelity　→　researchers　→ technology, tasks
- 結論
    - 構築された環境で行われる研究の妥当性を確保するためには、コンテキスト（研究の環境や条件やインタラクションの方法、心理的・社会的背景など）を中心的な分析構造として明示的に認識する必要がある
    - 構築された「内側」のコンテキスト層と現実の「外側」のコンテキスト層の間には一貫性がなければならない
    - 研究コンテキストの主観的解釈は、体系的な実証分析を通じて明らかにされるべき
    - コンテキストの分析には、その動態、例えばユーザーの期待や新奇効果に関連するものに焦点を当てるべき

## 自分の発表(10/25 Day3,Denmark)
- 今回の発表形式では、まず一部の発表者がTeaser talkで簡単に研究を紹介して、その後、興味を持った人がポスター発表を聞きに来る形でした。Teaser talkがあったおかげで、そしてDay1に深く交流したこともあって、私の実験の詳細を尋ねに来た人が多かったです。
### Teaser Talk1分間
- <img width="500" alt="スクリーンショット 2024-11-11 11 39 31" src="https://github.com/user-attachments/assets/fdea9afa-4c1e-4f91-abfd-19b60fef9914">
### ポスター1時間
- <img width="500" alt="スクリーンショット 2024-11-11 11 39 21" src="https://github.com/user-attachments/assets/4c9ddb10-8cb9-4804-9d8b-886c7bfbd7d1">
- いただいた質問
    - 数人「なぜ15日間の実験を選んだのか？」（関心が最も高い）
    - 実験の詳細
        - 「本当の悩みを話してもらうための工夫」（←参加者募集時に「ロボットとの簡単な悩み対話実験」であることを伝えている点や、対話の前に教示文を提供していることを説明しました。）
        - 「なぜ女子大学生を対象にしたのか？」
        - 「genderが結果に影響する可能性はあるか？」
        - 1分間のTeaser talkで対話実験の写真を見せたこともあり、ロボットの大きさや外観に興味を持った人が多く、「参加者はロボットのサイズに満足しているか？好きですか？」と聞かれ、実際の被験者のインタビュー結果から「サイズに満足して、好きです」と伝えました。
        - 「実験の様子」（←動画を用意しました。）
- その他
    - 多くの方が実験デザインについて確認し、「実験のデザインが良く、limitationsのまとめも適切である」と評価してくれました。
    - HAI班のGMと院ゼミの発表練習で、先生や院生の皆さんから「対話動画を用意すると良い」とアドバイスをいただきましたので、4つの対話ビデオを用意してポスター発表で来た人に見せました。これにより、来る人は実際の対話実験の様子を理解できたようです。
    - 他の多くの論文では、参加者数が90～160人と多いとわかりました。それに対して、私の実験は6人だけでしたが、15日間と長期間の実験だったため、少人数でも価値があると評価されました。もちろん、査読者から「参加者数の不足と実験期間が短いこと」が限界として指摘されていますので、今後は実験期間を延ばし、参加者数を増やすことが課題であると感じました。
    - 査読者から提案されたthematic analysisの追加分析は時間の関係で行わなかったです。ポスター発表した際に、テーマ分析についての詳細な助言や関連論文をいただきました。
    - 実験データが豊富で（インタビュー、対話、日記のテーマ分析など）、さらに分析を進める価値があると評価されました。
    - encouragementの種類の分類についても質問があり、博士課程での新しい実験に関して少し説明しました。分類については「重複がないようにすることが重要である」という意見もいただきました。
- 感想
    - 研究を行う際には細かいところまで確認し、自分の研究を十分に理解し、簡潔に理由を説明できることが非常に重要であると感じました。
    - 私の研究には意義があると感じました。
- 反省点
    - 会議のプログラム発表が遅く、通知もなく、会議の10日前に発表形式（oralかposterか）が分かりました。通知を待つより、もっと早めに問い合わせて準備に余裕を持つべきであると感じました。
    - みなさんがポスターの置き方が良くないと思い、横向きに置きたいと職員に伝えましたが、難しいです。
- 学会の最後
    - <img width="500" alt="スクリーンショット 2024-11-11 11 24 24" src="https://github.com/user-attachments/assets/6dcb5f80-46ee-45a5-a2e7-949006c71dac">
    - <img width="500" alt="スクリーンショット 2024-11-11 11 58 43" src="https://github.com/user-attachments/assets/6caaac5c-aa5d-48ea-ac1a-d9c467f7a45b">

# 全体的な感想
- 現在Social robotsに関する研究で関心が高いテーマとして、reliable、trust、emotional support、long-term、wellbeing、empathy、human likeness、real-world experiment、self-disclosure、children向けなどがあると感じました（ただ個人的な感想で、完全なリストではないです）。また、human robot interactionの研究では、多くの場合、human-humanのinteractionを基にして、human behaviorを考慮し、robotのbehaviorやdesignを取り入れて、social interactionにおけるロボットの役割を探求するというプロセスで行われていることがわかりました。
- この学会はSocial robots分野の内容に特化しているため、多くの発表がロボットとの対話ビデオを使っており、ビデオを用意すると理解しやすいと思います。
- 今回の会議に参加して、自分が少し成長できたと感じています。特に、普段から先生や先輩方に言われている「一つ一つの検討を大事にして、誰に聞かれても理由や妥当性を説明できるように時間をかけることが重要です。」という点がとても大切であると改めて実感しました。

# ICSR25
- <img width="500" alt="スクリーンショット 2024-11-11 11 26 25" src="https://github.com/user-attachments/assets/51e7f645-6eb5-4c68-852e-a93fa4b413ed">
